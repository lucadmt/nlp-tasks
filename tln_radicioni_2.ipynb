{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39664bitf9365f4bd6c94cd0b30113d0555f72e7",
   "display_name": "Python 3.9.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "import hashlib\n",
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from nltk.wsd import lesk\n",
    "from random import randint\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus.reader.framenet import PrettyList\n",
    "\n",
    "import common.prettyprint as pp \n",
    "import common.utils as utils\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "source": [
    "### 0. Individuazione di un set di Frame (FrameSet)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Il blocco seguente è stato preso (e in parte ri-adattato) dal notebook fornito a lezione per recuperare i frame dato un cognome."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frames_with_IDs():\n",
    "    for x in fn.frames():\n",
    "        print('{}\\t{}'.format(x.ID, x.name))\n",
    "\n",
    "def get_frams_IDs():\n",
    "    return [f.ID for f in fn.frames()]\n",
    "\n",
    "def getFrameSetForStudent(surname, list_len=5):\n",
    "    result = list()\n",
    "    nof_frames = len(fn.frames())\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % nof_frames)\n",
    "    print('\\nstudent: ' + surname)\n",
    "    framenet_IDs = get_frams_IDs()\n",
    "    i = 0\n",
    "    offset = 0 \n",
    "    seed(1)\n",
    "    while i < list_len:\n",
    "        fID = framenet_IDs[(base_idx+offset)%nof_frames]\n",
    "        result.append(fID)\n",
    "        f = fn.frame(fID)\n",
    "        fNAME = f.name\n",
    "        print('\\tID: {a:4d}\\tframe: {framename}'.format(a=fID, framename=fNAME))\n",
    "        offset = randint(0, nof_frames)\n",
    "        i += 1\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "student: D'Amato\n",
      "\tID: 2630\tframe: Standing_by\n",
      "\tID:  880\tframe: Being_in_operation\n",
      "\tID:   15\tframe: Separating\n",
      "\tID:   44\tframe: Volubility\n",
      "\tID: 2659\tframe: Distant_operated_IED\n"
     ]
    }
   ],
   "source": [
    "frameset = getFrameSetForStudent(\"D'Amato\")"
   ]
  },
  {
   "source": [
    "### 1. Consegna\n",
    "\n",
    "Per ogni frame nel FrameSet è necessario assegnare un WN synset ai seguenti elementi:\n",
    "\n",
    "- **Frame name** (nel caso si tratti di una multiword expression, come per esempio 'Religious_belief', disambiguare il termine principale, che in generale è il **sostantivo** se l'espressione è composta da NOUN+ADJ, e il **verbo** se l'espressione è composta da VERB+NOUN; in generale l'elemento fondamentale è individuato come il **reggente dell'espressione**.\n",
    "- **Frame Elements (FEs)** del frame; e \n",
    "- **Lexical Units (LUs)**.\n",
    "\n",
    "I contesti di disambiguazione possono essere creati utilizzando le definizioni disponibili (sia quella del frame, sia quelle dei FEs), ottenendo `Ctx(w)`, il contesto per FN terms `w`.\n",
    "\n",
    "Per quanto riguarda il contesto dei sensi presenti in WN è possibile selezionare glosse ed esempi dei sensi, e dei loro rispettivi iponimi e iperonimi, in modo da avere più informazione, ottenendo quindi il contesto di disambiguazione `Ctx(s)`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "La seguente funzione sfrutta spacy (una libreria) per fare la parsificazione. Il reggente, ovvero la radice dell'albero a dipendenze (trovato durante il parsing), viene restituito."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_root(multiword_exp):\n",
    "    doc = nlp(multiword_exp)\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'ROOT':\n",
    "            return token.text\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "source": [
    "Le seguenti funzioni sono state create per generare il contesto di un frame element.  \n",
    "* `get_disambiguation_ctx_for_fn` crea il contesto basandosi unicamente sulla definizione del frame.\n",
    "* `get_disambiguation_ctx_for_fes` crea il contesto basandosi sulle definizioni dei frame elements forniti in input\n",
    "* `get_combined_ctx` crea il contesto come unione del risultato delle precedenti funzioni"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disambiguation_ctx_for_fn(frame):\n",
    "    # Takes the frame definition, returns a Bag-of-words model\n",
    "    return utils.preprocess_phrase_nostem(frame.definition)\n",
    "\n",
    "def get_disambiguation_ctx_for_fes(frame_elements):\n",
    "    # Takes the frame elements, returns a Bag-of-words model for the whole definitions\n",
    "    result = list()\n",
    "    for key in frame_elements.keys():\n",
    "        result.append(utils.preprocess_phrase_nostem(frame_elements[key].definition))\n",
    "    return utils.flatten(result)\n",
    "\n",
    "def get_combined_ctx(frame):\n",
    "    # Takes a frame, returns a Bag-of-Words model for all the definitions in the frame\n",
    "    fn = get_disambiguation_ctx_for_fn(frame)\n",
    "    fes = get_disambiguation_ctx_for_fes(frame.FE)\n",
    "    return fn + fes"
   ]
  },
  {
   "source": [
    "La seguente funzione genera il contesto di disambiguazione per un certo synset. Per farlo, si basa:  \n",
    "1. Sulla definizione del synset fornito in input  \n",
    "2. Sugli esempi del synset fornito in input  \n",
    "3. Sulla definizione e esempi degli iperonimi diretti del synset fornito in input  \n",
    "4. Sulla definizione e esempi degli iponimi diretti del synset fornito in input  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_disambiguation_ctx_for_sysnet(synset):\n",
    "    # Given a synset, returns a Bag-of-Words model for its definition and examples\n",
    "    # as well as those of the direct hypernyms and direct hyponyms\n",
    "    context = synset.definition()\n",
    "    for example in synset.examples():\n",
    "        context += example\n",
    "\n",
    "    for hypernym in synset.hypernyms():\n",
    "        context += hypernym.definition()\n",
    "        for hyp_example in hypernym.examples():\n",
    "            context += hyp_example\n",
    "    \n",
    "    for hyponym in synset.hyponyms():\n",
    "        context += hyponym.definition()\n",
    "        for hypo_example in hyponym.examples():\n",
    "            context += hypo_example\n",
    "    return list(zip(*utils.word_frequencies(utils.preprocess_phrase_nostem(context))))[0]"
   ]
  },
  {
   "source": [
    "La seguente funzione trova **tutti** i synsets associabili ad un certo termine (tipicamente il nome di un frame). Si può scegliere di effettuare una ricerca con spacy oppure una cieca (attraverso il parametro `method`):\n",
    "* `method=spacy (default)`: Usa il parser di spacy per trovare il reggente della frase, dopodiché lo ricerca su WordNet fornendone i risultati in output\n",
    "* `method=dumb`: Dato il termine in input, lo separa in sottotermini (`.split('_')`) e cerca ognuno di essi in WordNet, restituendone i risultati\n",
    "Se per qualche ragione, il parametro 'method' non é specificato, non restituisce alcun risultato (`None`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_for_fn(frame_name: str, method='spacy'):\n",
    "    # given a frame name, returns all the relevant synsets\n",
    "    if method == 'spacy':\n",
    "        root = find_root(frame_name.replace('_', ' '))\n",
    "        return wn.synsets(root)\n",
    "    elif method == 'dumb':\n",
    "        strings = frame_name.split('_')\n",
    "        synsets = [wn.synsets(string) for string in strings]\n",
    "        return utils.flatten(synsets)\n",
    "    return None"
   ]
  },
  {
   "source": [
    "La prossima funzione é una specializzazione (più scarna) della precedente, pensata apposta per cercare le lexical units dei frame, in WordNet. Non dà alcuna libertà di scelta sul metodo con cui cercare su WordNet, poiché la struttura tipica di una lexical unit é simile a: `<termine>.<pos_tag>`. Di conseguenza, solo ciò che precede il '.' é rilevante. Quindi lo si recupera e lo si ricerca su WordNet, restituendone i risultati."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synset_for_lu(lu_name: str):\n",
    "    # given a frame name, returns all the relevant synsets\n",
    "    root = find_root(lu_name.split('.')[0])\n",
    "    return wn.synsets(root)"
   ]
  },
  {
   "source": [
    "La seguente funzione si occupa di creare il contesto per un frame element oppure per una lexical unit. Può procedere in questo modo, poiché nell'interfaccia FrameNet, sia i Frame Elements, che le Lexical Units sono specificate come dizionari (e quindi possiedono la stessa struttura).\n",
    "In modo simile alle precedenti funzioni per la generazione del contesto, prima di tutto si crea una stringa enorme con definizioni ed esempi per il `felu` (frame-element|lexical unit) in input, dopodiché si usa per creare un modello Bag-of-Words (funzione `utils.word_frequencies`), dopo aver fatto del preprocessing (funzione `utils.preprocess_phrase_nostem`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_for_felus(dictionary, felu):\n",
    "    # given a dictionary, representing frame elements or lexical units\n",
    "    # returns a disambiguation context (a Bag-of-Words model) made from definitions\n",
    "    # of the FE/LU and exemplars (if any)\n",
    "    result = \"\"\n",
    "    result += dictionary[felu].definition\n",
    "    try:\n",
    "        for ex in dictionary[felu].exemplars:\n",
    "            #print(ex.text)\n",
    "            result += ex.text\n",
    "    except KeyError as ke:\n",
    "        pass\n",
    "        #print(\"No exemplars here\")\n",
    "    return utils.word_frequencies(utils.preprocess_phrase_nostem(result))"
   ]
  },
  {
   "source": [
    "#### 3. Valutazione dell'output del sistema\n",
    "\n",
    "La valutazione dei risultati del mapping è fondamentale. A questo fine è necessario annotare con WN synset ID (ed eventualmente uno o due termini del synset) tutti gli elementi da mappare, e quindi \n",
    "\n",
    "- **Frame name** (nel caso si tratti di una multiword expression, come per esempio 'Religious_belief', cercare l'intera multiword su WordNet; se presente annotare con il relativo synset ID; diversamente disambiguare il termine principale, che in generale è il **sostantivo** se l'espressione è composta da NOUN+ADJ, e il **verbo** se l'espressione è composta da VERB+NOUN;\n",
    "- **Frame Elements (FEs)** del frame; e \n",
    "- **Lexical Units (LUs)**.\n",
    "\n",
    "La correttezza dell'output del sistema sviluppato è da calcolare in rapporto all'annotazione effettuata manualmente. Quindi l'annotazione costituisce un elemento molto importante nello svolgimento dell'esercitazione.\n",
    "\n",
    "Il programma implementato dovrà quindi fornire anche la funzionalità di valutazione, che confronterà i synset restituiti in output dal sistema con quelli annotati a mano dalla studentessa o dallo studente; su questa base deve essere calcolata l'accuratezza del sistema, semplicemente come rapporto degli elementi corretti sul totale degli elementi."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "La seguente lista contiene tutte le annotazioni manuali, di ogni componente del frame, per tutti i frame nel frameset. La variante contenente le 5 parole più prominenti del contesto del synset selezionato si trova in `./results/manual_annotations.txt`. Ogni frame disambiguato possiede la seguente struttura:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'frame_name': ('<Frame_Name>', 'synsetid'),\n",
    "    'frame_elements: {\n",
    "        '<element1>': 'synsetid'\n",
    "    }\n",
    "    'lexunits': {\n",
    "        '<lexunit1>': 'synsetid'\n",
    "    }\n",
    "}\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_frames = [{'frame_name': ('Standing_by', 'v.2611373'),'frame_elements': {'Protagonist': 'n.10172793','Salient_entity': 'n.1740','Time': 'n.15122231','Place': 'n.8513718','Duration': 'n.15133621','Manner': 'n.4928903','Expected_request': 'n.7185325','End_point': 'n.15180528','Explanation': 'n.6738281','Depictive': 'v.987071','Purpose': 'v.708980','Co-participant': 'n.10401829','Activity': 'n.407535'},'lexunits': {'stand by.v': 'v.2707125', 'on call.a': 'a.1651196', 'on station.a': 'a.1651196'}}, {'frame_name': ('Being_in_operation', 'n.14008806'), 'frame_elements': {'Device': 'n.3183080','Time': 'n.15122231','Place': 'n.8513718','Duration': 'n.15133621'}, 'lexunits': {'on.prep': 'r.69472','off.prep': 'r.193194','operate.v': 'v.1510827','operational.a': 's.833018'}}, {'frame_name': ('Separating', 'v.2467662'),'frame_elements': {'Whole': 'n.5869584','Parts': 'n.5867413','Part_1': 'n.5671974','Part_2': 'n.5671974','Agent': 'n.6332364','Criterion': 'n.5924920','Depictive': 'v.987071','Manner': 'n.4928903','Degree': 'n.5093890','Means': 'n.3733547','Result': 'n.6333285','Cause': 'n.7326557','Recipients': 'n.6333095','Time': 'n.15122231','Place': 'n.8513718','Instrument': 'n.6332731','Purpose': 'v.708980'},'lexunits': {'bisect.v': 'v.1550817','divide.v': 'v.1458973','part.v': 'v.2030158','partition.v': 'v.1563724','section.v': 'v.1563005','segment.v': 'v.1563005','segregate.v': 'v.494613','split.v': 'v.2467662', 'partition.n': 'n.397953', 'separate.v': 'v.2467662', 'sever.v': 'v.1560731'}}, {'frame_name': ('Volubility', 'n.4651195'), 'frame_elements': {'Speaker': 'n.10630188','Company': 'n.8264897','Text': 'n.6387980','Topic': 'n.6599788','Medium': 'n.6254669','Degree': 'n.5093890','Manner': 'n.4928903','Judge': 'n.10066732'}, 'lexunits': {'effusive.a': 's.806064','glib.a': 's.1874716','laconic.a': 's.547641','loquacious.a': 's.2384077','reticent.a': 's.2383709','silent.a': 's.501820','talkative.a': 's.496938','chatty.a': 's.496422','big mouth.n': None,'brusque.a': 's.640660','curt.a': 's.640660','expansive.a': 's.496938','garrulous.a': 's.2384077','gushing.a': 's.806064','gushy.a': 's.720524','mum.a': 's.501820','voluble.a': 'a.2383831','terse.a': 's.547641','uncommunicative.a': 'a.500569','loquacity.n': 'n.4651382','loudmouth.n': 'n.10274318','chatterbox.n': 'n.9911570','reticence.n': 'n.4652438','reserved.a': 'a.1987341','taciturn.a': 'a.2383380','mute.a': 's.152285','quiet.a': 'a.1918984'}}, {'frame_name': ('Distant_operated_IED', 'n.3565565'), 'frame_elements': {'Bomb': 'n.2866578','Use': 'n.5149325','Type': 'n.5840188','Material': 'n.14580897','Detonator': 'n.3182232','Part': 'n.3892891','Name': 'n.6333653','Time_of_creation': 'n.15122231','Creator': 'n.9614315','Descriptor': 'n.5823747','Target': 'n.10470460'}, 'lexunits': {'RCIED.n': None, 'CWIED.n': None, 'command IED.n': None}}]"
   ]
  },
  {
   "source": [
    "Si definisce lo score come:\n",
    "$$|ctx(w) \\cap ctx(s)|+1$$\n",
    "Per ragioni pratiche (dal momento che la stessa funzione serve per frame name, frame elements e lexical units, vengono passati direttamente i contesti invece che il synset e il frame term)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(ctx_s, ctx_w):\n",
    "    \"\"\"\n",
    "        Given contexts from a sense and a word, return the score\n",
    "    \"\"\"\n",
    "    return len(set(ctx_s).intersection(set(ctx_w))) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = [fn.frame(i) for i in frameset]"
   ]
  },
  {
   "source": [
    "Per evitare di rendere il codice ancora più illegibile, creo un alias `ss_ctx` per calcolare il contesto partendo da un synset, puntandolo alla funzione `get_big_disambiguation_ctx_for_sysnet`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_ctx = get_big_disambiguation_ctx_for_sysnet"
   ]
  },
  {
   "source": [
    "La seguente funzione si occupa di disambiguare _all'atto pratico_ il frame per intero. Per ogni elemento del frame (nome, elements e lexical units), procede allo stesso modo:  \n",
    "1. Recupera tutti i possibili synset (`get_synset_for_fn`) per una certa stringa  \n",
    "2. Calcola gli score per ogni coppia (synset, frame) (calcolandone prima i relativi contesti) e scrivendo il risultato in una lista di tuple `(<synset_scelto>, <score>)`  \n",
    "3. Ordina la lista per score decrescenti, e prende il primo elemento (il massimo)  \n",
    "4. Inserisce il risultato in un dizionario strutturato in modo simile ad `annotated_frames` (gli esempi annotati)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disambiguate_frame(frame):\n",
    "    result = {'frame_name': \"\", 'frame_elements': {}, 'lexunits': {}}\n",
    "\n",
    "    # Disambiguate frame name\n",
    "    synsets = get_synset_for_fn(frame.name)\n",
    "    name_ss_scores = [(synset, score(ss_ctx(synset), get_combined_ctx(frame))) for synset in synsets]\n",
    "    selected_name_ss = sorted(name_ss_scores, key = lambda x: x[1], reverse=True)[0][0]\n",
    "    result['frame_name'] = (frame.name, f\"{selected_name_ss.pos()}.{selected_name_ss.offset()}\")\n",
    "\n",
    "    # Disambiguate frame elements\n",
    "    for fe in frame.FE.keys():\n",
    "        fe_ss = get_synset_for_fn(fe)\n",
    "        fe_ss_scores = [(synset, score(ss_ctx(synset), get_context_for_felus(frame.FE, fe))) for synset in fe_ss]\n",
    "        selected_fe_ss = sorted(fe_ss_scores, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        result['frame_elements'][fe] = f\"{selected_fe_ss.pos()}.{selected_fe_ss.offset()}\"\n",
    "\n",
    "    # Disambiguate lexical units\n",
    "    for lu in frame.lexUnit.keys():\n",
    "        lu_ss = get_synset_for_lu(lu)\n",
    "        if (lu_ss):\n",
    "            lu_ss_scores = [(synset, score(ss_ctx(synset), get_context_for_felus(frame.lexUnit, lu))) for synset in lu_ss]\n",
    "            selected_lu_ss = sorted(lu_ss_scores, key = lambda x: x[1], reverse=True)[0][0]\n",
    "            result['lexunits'][lu] = f\"{selected_lu_ss.pos()}.{selected_lu_ss.offset()}\"\n",
    "        else:\n",
    "            result['lexunits'][lu] = None\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "source": [
    "La seguente misura di valutazione si basa sull'uguaglianza dei synset id (tra il frame disambiguato e l'annotazione manuale). Viene calcolata come il conteggio di annotazioni uguali (stesso synset id) sulla totalità degli elementi da annotare (`common_den`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_evaluation(frame, ground_truth):\n",
    "    # Given two dictionaries calculate accuracy as overlap between synset ids\n",
    "    common_den = 1 + len(frame['frame_elements']) + len(frame['lexunits'])\n",
    "    frame_score = 0\n",
    "    if frame['frame_name'][1] == ground_truth['frame_name'][1]:\n",
    "        frame_score += 1/common_den\n",
    "    for i in frame['frame_elements'].keys():\n",
    "        if frame['frame_elements'][i] == ground_truth['frame_elements'][i]:\n",
    "            frame_score += 1/common_den\n",
    "    \n",
    "    for j in frame['lexunits'].keys():\n",
    "        if frame['lexunits'][j] == ground_truth['lexunits'][j]:\n",
    "            frame_score += 1/common_den\n",
    "    return frame_score * 100"
   ]
  },
  {
   "source": [
    "Calcola l'accuratezza delle annotazioni (troncando il risultato alle ultime 2 cifre decimali per migliorare la leggibilità)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Standing_by: 41.17%\n",
      "Being_in_operation: 22.22%\n",
      "Separating: 17.24%\n",
      "Volubility: 63.88%\n",
      "Distant_operated_IED: 53.33%\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for idx in range(len(frames)):\n",
    "    disamb = disambiguate_frame(frames[idx])\n",
    "    r = math.trunc(equality_evaluation(disamb, annotated_frames[idx])*100)/100\n",
    "    print(f\"{disamb['frame_name'][0]}: {r}%\")\n",
    "    scores.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "39.568"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "source": [
    "Tutto sommato il sistema é piuttosto scarso, abbastanza sotto del dare una risposta casuale. In parte potrebbe essere spiegato dalla presenza di  definizioni che esprimono gli stessi concetti, ma sfruttando vocabolari diversi. Differenze che la banale sovrapposizione lessicale non é in grado di cogliere."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}